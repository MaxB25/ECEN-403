{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all Libraries needed to train as well as get information from the data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "import multiprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import pytds\n",
    "create_phrases = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to database to retrieve student and training resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:46:22: Opening socket to 34.69.166.47:1433\n",
      "INFO - 22:46:22: Sending PRELOGIN lib_ver=10b0000 enc_flag=2 inst_name=b'MSSQLServer' mars=False\n",
      "INFO - 22:46:22: Got PRELOGIN response crypt=2 mars=0\n",
      "INFO - 22:46:22: Sending LOGIN tds_ver=74000004 bufsz=4096 pid=11556 opt1=f0 opt2=2 opt3=8 cli_tz=-360 cli_lcid=1033 cli_host=DESKTOP-5D53OF5 lang= db=TBDraft\n",
      "INFO - 22:46:22: switched to database TBDraft\n",
      "INFO - 22:46:22: switched collation to Collation(lcid=1033, sort_id=52, ignore_case=True, ignore_accent=False, ignore_width=True, ignore_kana=True, binary=False, binary2=False, version=0)\n",
      "INFO - 22:46:22: switched language to us_english\n",
      "INFO - 22:46:22: Got LOGINACK tds_ver=74000004 srv_name=Microsoft SQL Server\u0000\u0000 srv_ver=f001052\n",
      "INFO - 22:46:22: Sending BEGIN TRAN il=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is working\n"
     ]
    }
   ],
   "source": [
    "connect_string = \"\"\n",
    "try:\n",
    "    conn = pytds.connect(server = '34.69.166.47', database = 'TBDraft', user = 'sqlserver', password='TBuilder')\n",
    "    print(\"{c} is working\".format(c=connect_string))\n",
    "except pytds.Error as ex:\n",
    "    print(\"{c} is not working\".format(c=connect_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:11:38: Sending query SELECT ALL * FROM TrainingResumes\n",
      "INFO - 00:11:38: Sending query SELECT ALL * FROM TrainingResumes\n",
      "INFO - 00:11:38: Sending query SELECT ALL * FROM StudentInformation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resumes Table\n",
      " Empty DataFrame\n",
      "Columns: [keyword, dataText]\n",
      "Index: [] \n",
      "\n",
      "Student Information Table\n",
      "    ID StudentName  GPA              Email  \\\n",
      "0   1    Student1  3.1  Student1@tamu.edu   \n",
      "1   2    Student2  3.2  Student2@tamu.edu   \n",
      "2   3    Student3  3.3  Student3@tamu.edu   \n",
      "3   4    Student4  3.4  Student4@tamu.edu   \n",
      "4   5    Student5  3.5  Student5@tamu.edu   \n",
      "\n",
      "                                       StudentResume          ProcessedData  \\\n",
      "0  b'%PDF-1.7\\r\\n%\\xb5\\xb5\\xb5\\xb5\\r\\n1 0 obj\\r\\n...  Resume in text format   \n",
      "1  b'%PDF-1.4\\n%\\xf6\\xe4\\xfc\\xdf\\n1 0 obj\\n<<\\n/T...  Resume in text format   \n",
      "2  b'%PDF-1.4\\n%\\xf6\\xe4\\xfc\\xdf\\n1 0 obj\\n<<\\n/T...  Resume in text format   \n",
      "3  b'%PDF-1.4\\n%\\xf6\\xe4\\xfc\\xdf\\n1 0 obj\\n<<\\n/T...  Resume in text format   \n",
      "4  b'%PDF-1.4\\n%\\xf6\\xe4\\xfc\\xdf\\n1 0 obj\\n<<\\n/T...  Resume in text format   \n",
      "\n",
      "      PhoneNumber  \n",
      "0  (111) 111-1111  \n",
      "1  (222) 222-2222  \n",
      "2  (333) 333-3333  \n",
      "3  (444) 444-4444  \n",
      "4  (555) 555-5555  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "##After connecting to database extract preprocessed information\n",
    "#Read in ID and resumes using pandas\n",
    "\n",
    "#This is how to create a two column list using two lists newlist = list(zip(numbers,letters))\n",
    "#Get data from server\n",
    "student_id = []\n",
    "student_resume = []\n",
    "cursor = conn.cursor()\n",
    "# cursor.execute(\"SELECT ALL * FROM StudentInformation\") #StudentInformation is the name of the table\n",
    "# for row in cursor:\n",
    "#         student_id.append(row.StudentName)\n",
    "#         student_resume(row.Resume)\n",
    "# #Store data in pandas data frame\n",
    "student_info = list(zip(student_id, student_resume))\n",
    "df = pd.DataFrame(student_info, columns=['ID', 'Processed Resume'])\n",
    "# df.head()\n",
    "cursor.execute(\"SELECT ALL * FROM TrainingResumes\")\n",
    "result = cursor.fetchall()\n",
    "for row in result:\n",
    "    print(row)\n",
    "    print('\\n')\n",
    "cursor.description\n",
    "df2 = pd.read_sql_query(\"SELECT ALL * FROM TrainingResumes\", conn)\n",
    "print(\"Training Resumes Table\\n\", df2, \"\\n\")\n",
    "df3 = pd.read_sql_query(\"SELECT ALL * FROM StudentInformation\", conn)\n",
    "print(\"Student Information Table\\n\", df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can either create phrases or not it would all depend on the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(create_phrases):\n",
    "    from gensim.models.phrases import Phraser, Phrases\n",
    "    sent = [row.split() for row in df['clean']] #Change change ['clean'] to whatever we actually label the columns as\n",
    "    phrases = Phrases(sent, min_count=5, progress_per=10000)\n",
    "    bigram = Phraser(phrases)\n",
    "    sentences = bigram[sent]\n",
    "    documents = [TaggedDocument(doc, tags=[df.ID[i]]) for i, doc in enumerate(sentences)]\n",
    "else:\n",
    "    documents = [TaggedDocument(doc, tags=[df.ID[i]]) for i, doc in enumerate(df.ID)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model and saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:45:46: collecting all words and their counts\n",
      "INFO - 22:45:46: collected 0 word types and 0 unique tags from a corpus of 0 examples and 0 words\n",
      "INFO - 22:45:46: Creating a fresh vocabulary\n",
      "INFO - 22:45:46: Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 0 unique words (0.0%% of original 0, drops 0)', 'datetime': '2021-11-22T22:45:46.117112', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 22:45:46: Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 0 word corpus (0.0%% of original 0, drops 0)', 'datetime': '2021-11-22T22:45:46.117581', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 22:45:46: deleting the raw counts dictionary of 0 items\n",
      "INFO - 22:45:46: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 22:45:46: Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 0 word corpus (0.0%% of prior 0)', 'datetime': '2021-11-22T22:45:46.117581', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 22:45:46: estimated required memory for 0 words and 30 dimensions: 0 bytes\n",
      "INFO - 22:45:46: resetting layer weights\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-f6e45b35e360>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbow_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.025\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.025\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd2v_model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, documents, corpus_file, vector_size, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, dv, dv_mapfile, comment, trim_rule, callbacks, window, epochs, shrink_windows, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_lockf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 0.0 values suppress word-backprop-updates; 1.0 allows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m         super(Doc2Vec, self).__init__(\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m             self.train(\n\u001b[0m\u001b[0;32m    427\u001b[0m                 \u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'start_doctags'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_doctags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m         super(Doc2Vec, self).train(\n\u001b[0m\u001b[0;32m    515\u001b[0m             \u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_training_sanity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m_check_training_sanity\u001b[1;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[0;32m   1529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# should be set by `build_vocab`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"you must first build vocabulary before training the model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1532\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"you must initialize vectors before training the model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(documents, dm = 0, dbow_words=1 , alpha=0.025, vector_size=30, min_alpha = 0.025, min_count = 5)\n",
    "model.save('d2v_model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69653a312dbe931d74f7dcdd7e6244916ba6f541c5453c763d9189f9df467eeb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
